# MediaPipe graph to detect/predict pose landmarks. (GPU input, and inference is
# executed on GPU.) This graph tries to skip pose detection as much as possible
# by using previously detected/predicted landmarks for new images.
#
# It is required that "pose_detection.tflite" is available at
# "mediapipe/modules/pose_detection/pose_detection.tflite"
# path during execution.
#
# It is required that "pose_landmark_lite.tflite" or
# "pose_landmark_full.tflite" or "pose_landmark_heavy.tflite" is available at
# "mediapipe/modules/pose_landmark/pose_landmark_lite.tflite" or
# "mediapipe/modules/pose_landmark/pose_landmark_full.tflite" or
# "mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite"
# path respectively during execution, depending on the specification in the
# MODEL_COMPLEXITY input side packet.
#
# EXAMPLE:
#   node {
#     calculator: "PoseLandmarkGpu"
#     input_side_packet: "MODEL_COMPLEXITY:model_complexity"
#     input_side_packet: "SMOOTH_LANDMARKS:smooth_landmarks"
#     input_side_packet: "ENABLE_SEGMENTATION:enable_segmentation"
#     input_side_packet: "SMOOTH_SEGMENTATION:smooth_segmentation"
#     input_side_packet: "USE_PREV_LANDMARKS:use_prev_landmarks"
#     input_stream: "IMAGE:image"
#     output_stream: "LANDMARKS:pose_landmarks"
#     output_stream: "SEGMENTATION_MASK:segmentation_mask"
#   }

type: "PoseLandmarkGpu"

# GPU image. (GpuBuffer)
input_stream: "IMAGE:image"

# Whether to filter landmarks across different input images to reduce jitter.
# If unspecified, functions as set to true. (bool)
input_side_packet: "SMOOTH_LANDMARKS:smooth_landmarks"

# Whether to predict the segmentation mask. If unspecified, functions as set to
# false. (bool)
input_side_packet: "ENABLE_SEGMENTATION:enable_segmentation"

# Complexity of the pose landmark model: 0, 1 or 2. Landmark accuracy as well as
# inference latency generally go up with the model complexity. If unspecified,
# functions as set to 1. (int)
input_side_packet: "MODEL_COMPLEXITY:model_complexity"

# Pose landmarks. (NormalizedLandmarkList)
# We have 33 landmarks (see pose_landmark_topology.svg), and there are other
# auxiliary key points.
# 0 - nose
# 1 - left eye (inner)
# 2 - left eye
# 3 - left eye (outer)
# 4 - right eye (inner)
# 5 - right eye
# 6 - right eye (outer)
# 7 - left ear
# 8 - right ear
# 9 - mouth (left)
# 10 - mouth (right)
# 11 - left shoulder
# 12 - right shoulder
# 13 - left elbow
# 14 - right elbow
# 15 - left wrist
# 16 - right wrist
# 17 - left pinky
# 18 - right pinky
# 19 - left index
# 20 - right index
# 21 - left thumb
# 22 - right thumb
# 23 - left hip
# 24 - right hip
# 25 - left knee
# 26 - right knee
# 27 - left ankle
# 28 - right ankle
# 29 - left heel
# 30 - right heel
# 31 - left foot index
# 32 - right foot index
#
# NOTE: if a pose is not present within the given ROI, for this particular
# timestamp there will not be an output packet in the LANDMARKS stream. However,
# the MediaPipe framework will internally inform the downstream calculators of
# the absence of this packet so that they don't wait for it unnecessarily.
output_stream: "LANDMARKS:passed_multi_pose_landmarks"

# Pose world landmarks. (LandmarkList)
# World landmarks are real-world 3D coordinates in meters with the origin at the
# center between hips. WORLD_LANDMARKS shares the same landmark topology as
# LANDMARKS. However, LANDMARKS provides coordinates (in pixels) of a 3D object
# projected onto the 2D image surface, while WORLD_LANDMARKS provides
# coordinates (in meters) of the 3D object itself.
output_stream: "WORLD_LANDMARKS:multi_pose_world_landmarks"

# Segmentation mask. (GpuBuffer in RGBA, with the same mask values in R and A)
# output_stream: "SEGMENTATION_MASK:segmentation_masks"

# Extra outputs (for debugging, for instance).
# Detected poses. (Detection)
output_stream: "DETECTION:pose_detections"
# Regions of interest calculated based on landmarks. (NormalizedRect)
output_stream: "ROI_FROM_LANDMARKS:pose_rects_from_landmarks" 

# Calculates size of the image.
node {
  calculator: "ImagePropertiesCalculator"
  input_stream: "IMAGE_GPU:image"
  output_stream: "SIZE:image_size"
}

# Detects poses.
node {
  calculator: "PoseDetectionGpu"
  input_stream: "IMAGE:image"
  output_stream: "DETECTIONS:all_pose_detections"
}

# Makes sure there are no more detections than provided num_pose (given through option).
node {
  calculator: "ClipDetectionVectorSizeCalculator"
  input_stream: "all_pose_detections"
  output_stream: "pose_detections"
  options {
    [mediapipe.ClipVectorSizeCalculatorOptions.ext] {
      max_vec_size: 5
    }
  }
}

# Outputs each element of pose_detections at a fake timestamp for the rest of
# the graph to process. Clones the image_size packet for each pose_detection at
# the fake timestamp. At the end of the loop, outputs the BATCH_END timestamp
# for downstream calculators to inform them that all elements in the vector have
# been processed.
node {
  calculator: "BeginLoopDetectionCalculator"
  input_stream: "ITERABLE:pose_detections"
  input_stream: "CLONE:image_size"
  output_stream: "ITEM:pose_detection"
  output_stream: "CLONE:image_size_for_pose_detection"
  output_stream: "BATCH_END:pose_detections_timestamp"
}

# Calculates region of interest based on pose detection, so that can be used
# to detect landmarks.
node {
  calculator: "PoseDetectionToRoi"
  input_stream: "DETECTION:pose_detection"
  input_stream: "IMAGE_SIZE:image_size_for_pose_detection"
  output_stream: "ROI:pose_rect_from_pose_detection"
}

# Collects a NormalizedRect for each hand into a vector. Upon receiving the
# BATCH_END timestamp, outputs the vector of NormalizedRect at the BATCH_END
# timestamp.
node {
  name: "EndLoopForPoseDetections"
  calculator: "EndLoopNormalizedRectCalculator"
  input_stream: "ITEM:pose_rect_from_pose_detection"
  input_stream: "BATCH_END:pose_detections_timestamp"
  output_stream: "ITERABLE:pose_rects_from_palm_detections"
}

node {
  calculator: "HyunsooForcedInputCalculator"
  input_stream: "INPUT_ITERABLE:pose_rects_from_palm_detections"
  output_stream: "OUTPUT_ITERABLE:forced_pose_rects"
  options: {
    [mediapipe.HyunsooForcedInputCalculatorOptions.ext] {
      number_detections: 2
    }
  }
}
node {
  calculator: "HyunsooLoggerCalculator"
  input_stream: "A:forced_pose_rects"
  output_stream: "A:passed_forced_pose_rects"
  options: {
    [mediapipe.HyunsooLoggerCalculatorOptions.ext] {
      log_tag: "Loop_before"
    }
  }
}

# Outputs each element of pose_rects at a fake timestamp for the rest of the
# graph to process. Clones image and image size packets for each
# single_pose_rect at the fake timestamp. At the end of the loop, outputs the
# BATCH_END timestamp for downstream calculators to inform them that all
# elements in the vector have been processed.
node {
  calculator: "BeginLoopNormalizedRectCalculator"
  input_stream: "ITERABLE:passed_forced_pose_rects"
  input_stream: "CLONE:0:image"
  input_stream: "CLONE:1:image_size"
  output_stream: "ITEM:single_pose_rect"
  output_stream: "CLONE:0:image_for_landmarks"
  output_stream: "CLONE:1:image_size_for_landmarks"
  output_stream: "BATCH_END:pose_rects_timestamp"
}
node {
  calculator: "HyunsooLoggerCalculator"
  input_stream: "A:single_pose_rect"
  output_stream: "A:passed_single_pose_rect"
  options: {
    [mediapipe.HyunsooLoggerCalculatorOptions.ext] {
      log_tag: "Loop_before_landmark"
    }
  }
}
# Detects pose landmarks within specified region of interest of the image.
node {
  calculator: "PoseLandmarkByRoiGpu"
  input_side_packet: "MODEL_COMPLEXITY:model_complexity"
  input_side_packet: "ENABLE_SEGMENTATION:enable_segmentation"
  input_stream: "IMAGE:image_for_landmarks"
  input_stream: "ROI:passed_single_pose_rect"
  output_stream: "LANDMARKS:unfiltered_pose_landmarks"
  output_stream: "AUXILIARY_LANDMARKS:unfiltered_auxiliary_landmarks"
  output_stream: "WORLD_LANDMARKS:unfiltered_world_landmarks"
  # output_stream: "SEGMENTATION_MASK:unfiltered_segmentation_mask"
}
node {
  calculator: "HyunsooLoggerCalculator"
  input_stream: "A:unfiltered_pose_landmarks"
  output_stream: "A:passed_unfiltered_pose_landmarks"
  options: {
    [mediapipe.HyunsooLoggerCalculatorOptions.ext] {
      log_tag: "Loop_after_landmark"
    }
  }
}


# Smoothes landmarks to reduce jitter.
node {
  calculator: "PoseLandmarkFiltering"
  input_side_packet: "ENABLE:smooth_landmarks"
  input_stream: "IMAGE_SIZE:image_size_for_landmarks"
  input_stream: "NORM_LANDMARKS:passed_unfiltered_pose_landmarks"
  input_stream: "AUX_NORM_LANDMARKS:unfiltered_auxiliary_landmarks"
  input_stream: "WORLD_LANDMARKS:unfiltered_world_landmarks"
  output_stream: "FILTERED_NORM_LANDMARKS:pose_landmarks"
  output_stream: "FILTERED_AUX_NORM_LANDMARKS:auxiliary_landmarks"
  output_stream: "FILTERED_WORLD_LANDMARKS:pose_world_landmarks"
}

# Collects a set of landmarks for each pose into a vector. Upon receiving the
# BATCH_END timestamp, outputs the vector of landmarks at the BATCH_END
# timestamp.
node {
  calculator: "EndLoopNormalizedLandmarkListVectorCalculator"
  input_stream: "ITEM:pose_landmarks"
  input_stream: "BATCH_END:pose_rects_timestamp"
  output_stream: "ITERABLE:multi_pose_landmarks"
}
node {
  calculator: "HyunsooLoggerCalculator"
  input_stream: "A:multi_pose_landmarks"
  output_stream: "A:passed_multi_pose_landmarks"
  options: {
    [mediapipe.HyunsooLoggerCalculatorOptions.ext] {
      log_tag: "Loop_after"
    }
  }
}

# Collects a set of world landmarks for each pose into a vector. Upon receiving
# the BATCH_END timestamp, outputs the vector of landmarks at the BATCH_END
# timestamp.
node {
  calculator: "EndLoopLandmarkListVectorCalculator"
  input_stream: "ITEM:pose_world_landmarks"
  input_stream: "BATCH_END:pose_rects_timestamp"
  output_stream: "ITERABLE:multi_pose_world_landmarks"
}

# Calculates region of interest based on the auxiliary landmarks, to be used in
# the subsequent image.
node {
  calculator: "PoseLandmarksToRoi"
  input_stream: "LANDMARKS:auxiliary_landmarks"
  input_stream: "IMAGE_SIZE:image_size"
  output_stream: "ROI:pose_rect_from_landmarks"
}

# Collects a NormalizedRect for each hand into a vector. Upon receiving the
# BATCH_END timestamp, outputs the vector of NormalizedRect at the BATCH_END
# timestamp.
node {
  calculator: "EndLoopNormalizedRectCalculator"
  input_stream: "ITEM:pose_rect_from_landmarks"
  input_stream: "BATCH_END:pose_rects_timestamp"
  output_stream: "ITERABLE:pose_rects_from_landmarks"
}